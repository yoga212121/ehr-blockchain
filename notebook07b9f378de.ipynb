{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9534879,"sourceType":"datasetVersion","datasetId":5807300},{"sourceId":9535008,"sourceType":"datasetVersion","datasetId":5807402}],"dockerImageVersionId":30775,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-03T07:38:42.969689Z","iopub.execute_input":"2024-10-03T07:38:42.970095Z","iopub.status.idle":"2024-10-03T07:38:43.423247Z","shell.execute_reply.started":"2024-10-03T07:38:42.970061Z","shell.execute_reply":"2024-10-03T07:38:43.422407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pip install imutils","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imutils import paths\nimport random\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nfrom torch.utils.data import *\nfrom torch.utils.data import *\nfrom torch import optim\nimport torch.nn as nn\nimport numpy as np\nimport argparse\nimport torch\nimport time\nimport cv2\nimport os\nfrom PIL import Image, ImageDraw, ImageFont\nimport sys","metadata":{"execution":{"iopub.status.busy":"2024-10-03T07:38:33.238988Z","iopub.execute_input":"2024-10-03T07:38:33.239421Z","iopub.status.idle":"2024-10-03T07:38:33.245771Z","shell.execute_reply.started":"2024-10-03T07:38:33.239382Z","shell.execute_reply":"2024-10-03T07:38:33.244777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prelims","metadata":{}},{"cell_type":"code","source":"CHARS = [\n         '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n         'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J',\n         'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',\n         'U', 'V', 'W', 'X', 'Y', 'Z'\n         ]\n\nCHARS_DICT = {char:i for i, char in enumerate(CHARS)}","metadata":{"execution":{"iopub.status.busy":"2024-10-03T07:38:48.391028Z","iopub.execute_input":"2024-10-03T07:38:48.391891Z","iopub.status.idle":"2024-10-03T07:38:48.398184Z","shell.execute_reply.started":"2024-10-03T07:38:48.391838Z","shell.execute_reply":"2024-10-03T07:38:48.397062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_size(imgpath):\n    shapeslist=[]\n    for img in os.listdir(imgpath):\n        try:\n            im = Image.open(imgpath+\"/\"+img)\n            shapeslist.append(im.size)\n        except:\n            pass\n    a = np.array(shapeslist)\n    heights = a.T[0]\n    widths = a.T[1]\n    heights.sort()\n    widths.sort()\n    img_h = int(np.median(heights))\n    img_w = int(np.median(widths))\n    return((img_h,img_w))","metadata":{"execution":{"iopub.status.busy":"2024-10-03T07:38:49.397489Z","iopub.execute_input":"2024-10-03T07:38:49.398605Z","iopub.status.idle":"2024-10-03T07:38:49.405824Z","shell.execute_reply.started":"2024-10-03T07:38:49.398556Z","shell.execute_reply":"2024-10-03T07:38:49.404733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def collate_fn(batch):\n    imgs = []\n    labels = []\n    lengths = []\n    for _, sample in enumerate(batch):\n        img, label, length = sample\n        imgs.append(torch.from_numpy(img))\n        labels.extend(label)\n        lengths.append(length)\n    labels = np.asarray(labels).flatten().astype(np.float32)\n\n    return (torch.stack(imgs, 0), torch.from_numpy(labels), lengths)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T07:38:50.759934Z","iopub.execute_input":"2024-10-03T07:38:50.761042Z","iopub.status.idle":"2024-10-03T07:38:50.767921Z","shell.execute_reply.started":"2024-10-03T07:38:50.760981Z","shell.execute_reply":"2024-10-03T07:38:50.766804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LPRDataLoader(Dataset):\n    def __init__(self, img_dir, imgSize, lpr_max_len, PreprocFun=None):\n        self.img_dir = img_dir\n        self.img_paths = []\n        for i in range(len(img_dir)):\n            self.img_paths += [el for el in paths.list_images(img_dir[i])]\n        print(\"1dir found, size: \",len(self.img_paths))\n        random.shuffle(self.img_paths)\n        self.img_size = imgSize\n        self.lpr_max_len = lpr_max_len\n        if PreprocFun is not None:\n            self.PreprocFun = PreprocFun\n        else:\n            self.PreprocFun = self.transform\n\n    def __len__(self):\n        return len(self.img_paths)\n\n    def __getitem__(self, index):\n        filename = self.img_paths[index]\n        try:\n            Image = cv2.imread(filename)\n            if Image is None:\n                raise ValueError(f\"Image at {filename} could not be loaded.\")\n            Image = cv2.resize(Image, self.img_size)\n            Image = self.PreprocFun(Image)\n            basename = os.path.basename(filename)\n            imgname, suffix = os.path.splitext(basename)\n            imgname = ''.join(e for e in imgname if e.isalnum())\n            label = [CHARS_DICT[c] for c in imgname.upper() if c in CHARS_DICT]\n\n            if not self.check(label):\n                print(f\"Invalid label for image {filename}: {label}\")\n                return None  # Skip this sample\n\n            return Image, label, len(label)\n\n        except Exception as e:\n            print(f\"Error in image: {filename}, Error: {e}\")\n            return None  # or handle it differently\n\n            \n    \n    def transform(self, img):\n        img = img.astype('float32')\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        img -= 127.5\n        img *= 0.0078125\n        #thresh, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY)\n        img = np.reshape(img, img.shape + (1,))\n        img = np.transpose(img, (2, 0, 1))\n        return img\n\n    def check(self, label):\n        if len(label)<4:\n            print(\"Error label, Please check!\")\n            return False\n        else:\n            return True","metadata":{"execution":{"iopub.status.busy":"2024-10-03T09:42:24.252049Z","iopub.execute_input":"2024-10-03T09:42:24.252896Z","iopub.status.idle":"2024-10-03T09:42:24.445592Z","shell.execute_reply.started":"2024-10-03T09:42:24.252852Z","shell.execute_reply":"2024-10-03T09:42:24.444532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LPRNet","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch\n\nclass small_basic_block(nn.Module):\n    def __init__(self, ch_in, ch_out):\n        super(small_basic_block, self).__init__()\n        self.block = nn.Sequential(\n            nn.Conv2d(ch_in, ch_out // 4, kernel_size=1),\n            nn.ReLU(),\n            nn.Conv2d(ch_out // 4, ch_out // 4, kernel_size=(3, 1), padding=(1, 0)),\n            nn.ReLU(),\n            nn.Conv2d(ch_out // 4, ch_out // 4, kernel_size=(1, 3), padding=(0, 1)),\n            nn.ReLU(),\n            nn.Conv2d(ch_out // 4, ch_out, kernel_size=1),\n        )\n    def forward(self, x):\n        return self.block(x)\n\nclass LPRNet(nn.Module):\n    def __init__(self, lpr_max_len, phase, class_num, dropout_rate):\n        super(LPRNet, self).__init__()\n        torch.cuda.empty_cache()\n        self.phase = phase\n        self.lpr_max_len = lpr_max_len\n        self.class_num = class_num\n        self.backbone = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1), # 0\n            nn.BatchNorm2d(num_features=64),\n            nn.ReLU(),  # 2\n            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 1, 1)),\n            small_basic_block(ch_in=64, ch_out=128),    # *** 4 ***\n            nn.BatchNorm2d(num_features=128),\n            nn.ReLU(),  # 6\n            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(2, 1, 2)),\n            small_basic_block(ch_in=64, ch_out=256),   # 8\n            nn.BatchNorm2d(num_features=256),\n            nn.ReLU(),  # 10\n            small_basic_block(ch_in=256, ch_out=256),   # *** 11 ***\n            nn.BatchNorm2d(num_features=256),   # 12\n            nn.ReLU(),\n            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(4, 1, 2)),  # 14\n            nn.Dropout(dropout_rate),\n            nn.Conv2d(in_channels=64, out_channels=256, kernel_size=(1, 4), stride=1),  # 16\n            nn.BatchNorm2d(num_features=256),\n            nn.ReLU(),  # 18\n            nn.Dropout(dropout_rate),\n            nn.Conv2d(in_channels=256, out_channels=class_num, kernel_size=(13, 1), stride=1), # 20\n            nn.BatchNorm2d(num_features=class_num),\n            nn.ReLU(),  # *** 22 ***\n        )\n        self.container = nn.Sequential(\n            nn.Conv2d(in_channels=448+self.class_num, out_channels=self.class_num, kernel_size=(1, 1), stride=(1, 1)),\n            # nn.BatchNorm2d(num_features=self.class_num),\n            # nn.ReLU(),\n            # nn.Conv2d(in_channels=self.class_num, out_channels=self.lpr_max_len+1, kernel_size=3, stride=2),\n            # nn.ReLU(),\n        )\n\n    def forward(self, x):\n        keep_features = list()\n        for i, layer in enumerate(self.backbone.children()):\n            x = layer(x)\n            if i in [2, 6, 13, 22]: # [2, 4, 8, 11, 22]\n                keep_features.append(x)\n\n        global_context = list()\n        for i, f in enumerate(keep_features):\n            if i in [0, 1]:\n                f = nn.AvgPool2d(kernel_size=5, stride=5)(f)\n            if i in [2]:\n                f = nn.AvgPool2d(kernel_size=(4, 10), stride=(4, 2))(f)\n            f_pow = torch.pow(f, 2)\n            f_mean = torch.mean(f_pow)\n            f = torch.div(f, f_mean)\n            global_context.append(f)\n\n        x = torch.cat(global_context, 1)\n        x = self.container(x)\n        logits = torch.mean(x, dim=2)\n\n        return logits\n\ndef build_lprnet(lpr_max_len=15, phase=False, class_num=36, dropout_rate=0.5):\n\n    Net = LPRNet(lpr_max_len, phase, class_num, dropout_rate)\n\n    if phase == \"train\":\n        return Net.train()\n    else:\n        return Net.eval()","metadata":{"execution":{"iopub.status.busy":"2024-10-03T07:38:53.899273Z","iopub.execute_input":"2024-10-03T07:38:53.900026Z","iopub.status.idle":"2024-10-03T07:38:53.922992Z","shell.execute_reply.started":"2024-10-03T07:38:53.899981Z","shell.execute_reply":"2024-10-03T07:38:53.922016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(torch.cuda.is_available())","metadata":{"execution":{"iopub.status.busy":"2024-10-03T07:38:55.725363Z","iopub.execute_input":"2024-10-03T07:38:55.726368Z","iopub.status.idle":"2024-10-03T07:38:55.790256Z","shell.execute_reply.started":"2024-10-03T07:38:55.72632Z","shell.execute_reply":"2024-10-03T07:38:55.789247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nimport pandas as pd\nimport numpy as np\nimport cv2 as cv\nfrom PIL import Image\nimport argparse\nimport re","metadata":{"execution":{"iopub.status.busy":"2024-10-03T08:31:37.794652Z","iopub.execute_input":"2024-10-03T08:31:37.79567Z","iopub.status.idle":"2024-10-03T08:31:37.800735Z","shell.execute_reply.started":"2024-10-03T08:31:37.795626Z","shell.execute_reply":"2024-10-03T08:31:37.799598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def label_check(label):\n    if len(label) < 8:\n        return 0\n\n    if label[0:2] == 'DL':\n        delhi_pt = r\"\\d{4,4}$\"  # Use raw string for regex\n        dlval = re.search(delhi_pt, label)\n        if dlval is None or len(dlval.group()) < 8:\n            return 0\n        else:\n            return 1\n    \n    # General pattern for license plates\n    pattern = r\"(([A-Za-z]{2,3})(-?)([0-9]{1,2})(-?)([A-Za-z]{1,3})(-?)([0-9]{1,4}))|(([A-Za-z]{2,3})(-?)([0-9]{1,4}))\"\n    val = re.search(pattern, label)\n    if val is None or len(val.group()) < 8:\n        return 0\n    else:\n        return 1","metadata":{"execution":{"iopub.status.busy":"2024-10-03T09:00:22.24657Z","iopub.execute_input":"2024-10-03T09:00:22.247314Z","iopub.status.idle":"2024-10-03T09:00:22.254791Z","shell.execute_reply.started":"2024-10-03T09:00:22.247265Z","shell.execute_reply":"2024-10-03T09:00:22.253782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef summarize_image_widths(image_dir):\n    image_widths = []\n\n    # Iterate through all image files in the directory\n    for root, dirs, files in os.walk(image_dir):\n        for file in files:\n            if file.endswith(('.png', '.jpg', '.jpeg')):  # Add other image formats if needed\n                img_path = os.path.join(root, file)\n                img = cv2.imread(img_path)\n                \n                if img is not None:\n                    height, width, _ = img.shape\n                    image_widths.append(width)\n                else:\n                    print(f\"Error loading image: {img_path}\")\n\n    # Calculate statistics\n    if len(image_widths) == 0:\n        print(\"No images found in the directory.\")\n        return\n\n    min_width = np.min(image_widths)\n    max_width = np.max(image_widths)\n    avg_width = np.mean(image_widths)\n    median_width = np.median(image_widths)\n\n    print(f\"Total images processed: {len(image_widths)}\")\n    print(f\"Min Width: {min_width}\")\n    print(f\"Max Width: {max_width}\")\n    print(f\"Average Width: {avg_width:.2f}\")\n    print(f\"Median Width: {median_width}\")\n\n    # Plot a histogram to visualize width variation\n    plt.figure(figsize=(10, 6))\n    plt.hist(image_widths, bins=20, color='blue', alpha=0.7, edgecolor='black')\n    plt.title('Distribution of Image Widths')\n    plt.xlabel('Image Width (pixels)')\n    plt.ylabel('Frequency')\n    plt.grid(True)\n    plt.show()\n\n    return {\n        'min_width': min_width,\n        'max_width': max_width,\n        'avg_width': avg_width,\n        'median_width': median_width\n    }\n\n# Example usage\nimage_dir = '/kaggle/input/images/images'  # Replace with your image directory path\nsummary = summarize_image_widths(image_dir)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-03T09:00:23.386433Z","iopub.execute_input":"2024-10-03T09:00:23.387514Z","iopub.status.idle":"2024-10-03T09:00:25.016356Z","shell.execute_reply.started":"2024-10-03T09:00:23.387456Z","shell.execute_reply":"2024-10-03T09:00:25.015299Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\n\ndef pad_image(image, target_width):\n    \"\"\"Pad the image to the target width.\"\"\"\n    height, width = image.shape[:2]\n    if width < target_width:\n        # Calculate the padding needed on each side\n        padding = (target_width - width) // 2\n        image = cv.copyMakeBorder(image, 0, 0, padding, padding, cv.BORDER_CONSTANT, value=(0, 0, 0))\n    return image\n\ndef resize_image_to_target(image, target_size=(94, 24)):\n    \"\"\"Resize the image to the target size if its width is larger.\"\"\"\n    height, width = image.shape[:2]\n    if width > target_size[0]:\n        # Resize image while keeping the aspect ratio\n        image = cv.resize(image, target_size, interpolation=cv.INTER_AREA)\n    \n    return image","metadata":{"execution":{"iopub.status.busy":"2024-10-03T09:10:34.096571Z","iopub.execute_input":"2024-10-03T09:10:34.097947Z","iopub.status.idle":"2024-10-03T09:10:34.108006Z","shell.execute_reply.started":"2024-10-03T09:10:34.097876Z","shell.execute_reply":"2024-10-03T09:10:34.106699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nimport os\n\ndef clear_working_directory():\n    working_dir = '/kaggle/working'\n    \n    # Iterate through all files and directories in the working directory\n    for filename in os.listdir(working_dir):\n        file_path = os.path.join(working_dir, filename)\n        \n        try:\n            # Check if it's a file or directory and delete accordingly\n            if os.path.isfile(file_path) or os.path.islink(file_path):\n                os.unlink(file_path)  # Remove the file\n#                 print(f\"Deleted file: {file_path}\")\n            elif os.path.isdir(file_path):\n                shutil.rmtree(file_path)  # Remove the directory and all its contents\n#                 print(f\"Deleted directory: {file_path}\")\n        except Exception as e:\n            print(f\"Failed to delete {file_path}. Reason: {e}\")\n\n# Run the function to clear the working directory\nclear_working_directory()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-03T09:10:40.713473Z","iopub.execute_input":"2024-10-03T09:10:40.713943Z","iopub.status.idle":"2024-10-03T09:10:40.749987Z","shell.execute_reply.started":"2024-10-03T09:10:40.7139Z","shell.execute_reply":"2024-10-03T09:10:40.749037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess():\n    odr = os.path.expanduser('/kaggle/input/images/images')\n    writable_dir = '/kaggle/working/processed_images'\n    optimal_min_width = 100  # Modal width\n\n    # Create writable directory if it doesn't exist\n    if not os.path.exists(writable_dir):\n        os.makedirs(writable_dir)\n\n    if not os.path.exists(odr):\n        print(f\"Directory does not exist: {odr}\")\n        return\n\n    total_images = 0\n    discarded_count = 0\n\n    print(f\"Processing images in the directory: {odr}\")\n\n    for dirs in os.listdir(odr):\n        dir_path = os.path.join(odr, dirs)\n        if not os.path.isdir(dir_path):\n            print(f\"Skipping non-directory item: {dirs}\")\n            continue\n\n        # Create corresponding directory in writable directory\n        writable_subdir = os.path.join(writable_dir, dirs)\n        if not os.path.exists(writable_subdir):\n            os.makedirs(writable_subdir)\n\n        for img in os.listdir(dir_path):\n            total_images += 1\n            ipath = os.path.join(dir_path, img)\n            img_name, _ = os.path.splitext(img)  # Get base image name without extension\n\n            # The label is now the same as the filename without extension\n            label = img_name\n\n            # Perform label check\n            if not label_check(label):\n                print(f\"Invalid label: {label}. Discarding image: {img}\")\n                discarded_count += 1\n                continue\n\n            # Read the image using OpenCV\n            image = cv.imread(ipath)\n            if image is None:\n                print(f\"Failed to load image: {img}. Discarding.\")\n                discarded_count += 1\n                continue\n\n            # Check size and pad if necessary\n            height, width = image.shape[:2]\n            # Pad or resize image based on its width\n            if width < optimal_min_width:\n                image = pad_image(image, optimal_min_width)  # Pad the image if below target width\n            elif width > optimal_min_width:\n                image = resize_image_to_target(image) \n\n            # Clean the label and create a new file path in writable directory\n            label_clean = ''.join(e for e in label if e.isalnum())\n            tpath = os.path.join(writable_subdir, f\"{label_clean}.jpg\")  # Assuming '.jpg' extension\n\n            # Check if target path already exists\n            if os.path.exists(tpath):\n                # If both files exist, compare sizes before discarding one\n                if os.path.getsize(tpath) == os.path.getsize(ipath):\n                    print(f\"Duplicate found, keeping original: {img}\")\n                    continue\n                else:\n                    print(f\"Replacing duplicate with smaller file: {img}\")\n                    os.remove(tpath)  # Remove the existing larger file\n\n            # Save the processed image to writable directory\n            try:\n                cv.imwrite(tpath, image)\n                print(f\"Saved {tpath}\")\n            except Exception as e:\n                print(f\"Error saving image: {img}. Reason: {e}\")\n                continue\n\n    print(f\"Processed {total_images} images.\")\n    print(f\"Discarded {discarded_count} images due to invalid label or size.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-03T09:12:35.652281Z","iopub.execute_input":"2024-10-03T09:12:35.652718Z","iopub.status.idle":"2024-10-03T09:12:35.669004Z","shell.execute_reply.started":"2024-10-03T09:12:35.652675Z","shell.execute_reply":"2024-10-03T09:12:35.667735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocess()","metadata":{"execution":{"iopub.status.busy":"2024-10-03T09:12:37.141186Z","iopub.execute_input":"2024-10-03T09:12:37.141593Z","iopub.status.idle":"2024-10-03T09:12:38.3046Z","shell.execute_reply.started":"2024-10-03T09:12:37.141554Z","shell.execute_reply":"2024-10-03T09:12:38.303486Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def sparse_tuple_for_ctc(T_length, lengths):\n    input_lengths = []\n    target_lengths = []\n\n    for ch in lengths:\n        input_lengths.append(T_length)\n        target_lengths.append(ch)\n\n    return tuple(input_lengths), tuple(target_lengths)\n\ndef adjust_learning_rate(optimizer, cur_epoch, base_lr, lr_schedule):\n    lr = 0\n#     print(\"Original learning rate schedule:\", lr_schedule)\n\n    # Convert all valid elements to integers\n    valid_lr_schedule = []\n    for e in lr_schedule:\n        try:\n            valid_lr_schedule.append(int(e))\n        except ValueError:\n            print(f\"Skipping non-numeric value: {e}\")\n\n    for i, e in enumerate(valid_lr_schedule):\n        if cur_epoch < e:\n            lr = base_lr * (0.1 ** i)\n            break\n    \n    # Update the learning rate for the optimizer\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n    \n    return lr\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-03T09:54:20.583101Z","iopub.execute_input":"2024-10-03T09:54:20.584061Z","iopub.status.idle":"2024-10-03T09:54:20.593617Z","shell.execute_reply.started":"2024-10-03T09:54:20.584012Z","shell.execute_reply":"2024-10-03T09:54:20.592366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import argparse\nimport os\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom torch.utils.data import DataLoader\nimport sys\n\n# Example of modified argument parsing\ndef get_parser():\n    parser = argparse.ArgumentParser(description='Parameters to train the LPRNet model.')\n    \n    parser.add_argument('--max_epoch', type=int, default=50)\n    parser.add_argument('--img_size', type=int, nargs=2, default=(94, 24),\n                        help='The image size as two integers, width and height.')\n    parser.add_argument('--train_img_dirs', type=str, default='/kaggle/working/processed_images/train')\n    parser.add_argument('--test_img_dirs', type=str, default='/kaggle/working/processed_images/test')\n    parser.add_argument('--dropout_rate', type=float, default=0.5)\n    parser.add_argument('--learning_rate', type=float, default=0.001)\n    parser.add_argument('--lpr_max_len', type=int, default=18)\n    parser.add_argument('--train_batch_size', type=int, default=32)\n    parser.add_argument('--test_batch_size', type=int, default=32)\n    parser.add_argument('--phase_train', type=str, default='train')\n    parser.add_argument('--num_workers', type=int, default=4)\n    parser.add_argument('--cuda', action='store_true', default=False)\n    parser.add_argument('--resume_epoch', type=int, default=0)\n    parser.add_argument('--save_interval', type=int, default=100)\n    parser.add_argument('--test_interval', type=int, default=100)\n    parser.add_argument('--momentum', type=float, default=0.9)\n    parser.add_argument('--weight_decay', type=float, default=1e-4)\n    parser.add_argument('--lr_schedule', type= list[int], default = [20, 40])  # Epochs where the learning rate will decay\n    parser.add_argument('--show', type=bool, default=True,\n                        help='Displays images with labels and targets.')\n    parser.add_argument('--save_folder', type=str, default='./saved_models/')\n    parser.add_argument('--pretrained_model', type=str, default='/kaggle/input/pretrained/Final_LPRNet_model.pth')\n\n    # Check if we are running in Jupyter Notebook\n    if 'ipykernel' in sys.modules:\n        return parser.parse_args([])  # Parse with no arguments\n\n    return parser.parse_args()  # Normal parsing for command line","metadata":{"execution":{"iopub.status.busy":"2024-10-03T10:18:41.28121Z","iopub.execute_input":"2024-10-03T10:18:41.282089Z","iopub.status.idle":"2024-10-03T10:18:41.299557Z","shell.execute_reply.started":"2024-10-03T10:18:41.282043Z","shell.execute_reply":"2024-10-03T10:18:41.29824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Greedy_Decode_Eval(Net, datasets, args):\n    epoch_size = len(datasets) // args.test_batch_size\n    batch_iterator = iter(DataLoader(datasets, args.test_batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=collate_fn))\n\n    Tp = 0\n    Tn_1 = 0\n    Tn_2 = 0\n    t1 = time.time()\n    \n    # Counter for limiting the number of displayed images\n    images_shown = 0\n    max_images_to_show = 2\n\n    for i in range(epoch_size):\n        images, labels, lengths = next(batch_iterator)\n        start = 0\n\n        # Creating targets as an object array to accommodate varying lengths\n        targets = np.empty(len(lengths), dtype=object)\n        for idx, length in enumerate(lengths):\n            targets[idx] = labels[start:start + length]\n            start += length\n        \n        imgs = images.numpy().copy()\n\n        if args.cuda:\n            images = Variable(images.cuda())\n        else:\n            images = Variable(images)\n\n        # Forward pass\n        prebs = Net(images)\n        prebs = prebs.cpu().detach().numpy()\n        preb_labels = []\n\n        for i in range(prebs.shape[0]):\n            preb = prebs[i, :, :]\n            preb_label = []\n            for j in range(preb.shape[1]):\n                preb_label.append(np.argmax(preb[:, j], axis=0))\n            no_repeat_blank_label = []\n            pre_c = preb_label[0]\n            if pre_c != len(CHARS) - 1:\n                no_repeat_blank_label.append(pre_c)\n            for c in preb_label:\n                if (pre_c == c) or (c == len(CHARS) - 1):\n                    if c == len(CHARS) - 1:\n                        pre_c = c\n                    continue\n                no_repeat_blank_label.append(c)\n                pre_c = c\n            preb_labels.append(no_repeat_blank_label)\n\n        for i, label in enumerate(preb_labels):\n            # Show image only if images_shown is less than max_images_to_show\n            if args.show and images_shown < max_images_to_show:\n                print(f\"Showing image {i}, label: {label}, target: {targets[i]}\")\n                if imgs[i].shape[0] == 0 or imgs[i].shape[1] == 0:\n                    print(f\"Empty image at index {i}, skipping...\")\n                    continue\n                show(imgs[i], label, targets[i])\n                images_shown += 1  # Increment counter\n\n            if len(label) != len(targets[i]):\n                Tn_1 += 1\n                continue\n            if (np.asarray(targets[i]) == np.asarray(label)).all():\n                Tp += 1\n            else:\n                Tn_2 += 1\n\n        # Break the loop early if the desired number of images has been shown\n        if images_shown >= max_images_to_show:\n            break\n\n    total_predictions = Tp + Tn_1 + Tn_2\n    Acc = Tp * 1.0 / total_predictions if total_predictions > 0 else 0.0\n\n    print(\"[Info] Test Accuracy: {} [{}:{}:{}:{}]\".format(Acc, Tp, Tn_1, Tn_2, total_predictions))\n    t2 = time.time()\n    print(\"[Info] Test Speed: {}s 1/{}]\".format((t2 - t1) / len(datasets), len(datasets)))","metadata":{"execution":{"iopub.status.busy":"2024-10-03T10:19:50.189376Z","iopub.execute_input":"2024-10-03T10:19:50.190464Z","iopub.status.idle":"2024-10-03T10:19:50.210044Z","shell.execute_reply.started":"2024-10-03T10:19:50.190417Z","shell.execute_reply":"2024-10-03T10:19:50.208843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train():\n    args = get_parser()\n\n    T_length = 18 # args.lpr_max_len\n    epoch = 0 + args.resume_epoch\n    loss_val = 0\n\n    if not os.path.exists(args.save_folder):\n        os.mkdir(args.save_folder)\n\n    lprnet = build_lprnet(lpr_max_len=args.lpr_max_len, phase=args.phase_train, class_num=len(CHARS), dropout_rate=args.dropout_rate)\n    device = torch.device(\"cuda:0\" if args.cuda else \"cpu\")\n    lprnet.to(device)\n    print(\"Successful to build network!\")\n\n    # load pretrained model\n    if args.pretrained_model:\n        lprnet.load_state_dict(torch.load(args.pretrained_model))\n        print(\"load pretrained model successful!\")\n    else:\n        def xavier(param):\n            nn.init.xavier_uniform(param)\n\n        def weights_init(m):\n            for key in m.state_dict():\n                if key.split('.')[-1] == 'weight':\n                    if 'conv' in key:\n                        nn.init.kaiming_normal_(m.state_dict()[key], mode='fan_out')\n                    if 'bn' in key:\n                        m.state_dict()[key][...] = xavier(1)\n                elif key.split('.')[-1] == 'bias':\n                    m.state_dict()[key][...] = 0.01\n\n        lprnet.backbone.apply(weights_init)\n        lprnet.container.apply(weights_init)\n        print(\"initial net weights successful!\")\n\n    # define optimizer\n    # optimizer = optim.SGD(lprnet.parameters(), lr=args.learning_rate,\n    #                       momentum=args.momentum, weight_decay=args.weight_decay)\n    optimizer = optim.RMSprop(lprnet.parameters(), lr=args.learning_rate, alpha = 0.9, eps=1e-08,\n                         momentum=args.momentum, weight_decay=args.weight_decay)\n    train_img_dirs = os.path.expanduser(args.train_img_dirs)\n    test_img_dirs = os.path.expanduser(args.test_img_dirs)\n    #train_imgsize = get_size(train_img_dirs)\n    #test_imgsize = get_size(test_img_dirs)\n    train_dataset = LPRDataLoader(train_img_dirs.split(','), args.img_size, args.lpr_max_len)\n    test_dataset = LPRDataLoader(test_img_dirs.split(','), args.img_size, args.lpr_max_len)\n\n    epoch_size = len(train_dataset) // args.train_batch_size\n    max_iter = args.max_epoch * epoch_size\n    \n    print(epoch_size, max_iter)\n    \n    ctc_loss = nn.CTCLoss(blank=len(CHARS)-1, reduction='mean') # reduction: 'none' | 'mean' | 'sum'\n\n    if args.resume_epoch > 0:\n        start_iter = args.resume_epoch * epoch_size\n    else:\n        start_iter = 0\n\n    for iteration in range(start_iter, max_iter):\n        if iteration % epoch_size == 0:\n            # create batch iterator\n            batch_iterator = iter(DataLoader(train_dataset, args.train_batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=collate_fn))\n            loss_val = 0\n            epoch += 1\n\n        if iteration !=0 and iteration % args.save_interval == 0:\n            torch.save(lprnet.state_dict(), args.save_folder + 'LPRNet_' + '_iteration_' + repr(iteration) + '.pth')\n\n        if (iteration + 1) % args.test_interval == 0:\n            Greedy_Decode_Eval(lprnet, test_dataset, args)\n            # lprnet.train() # should be switch to train mode\n\n        start_time = time.time()\n        # load train data\n        images, labels, lengths = next(batch_iterator)\n        # labels = np.array([el.numpy() for el in labels]).T\n        # get ctc parameters\n        input_lengths, target_lengths = sparse_tuple_for_ctc(T_length, lengths)\n        # update lr\n        lr = adjust_learning_rate(optimizer, epoch, args.learning_rate, args.lr_schedule)\n\n        if args.cuda:\n            images = Variable(images, requires_grad=False).cuda()\n            labels = Variable(labels, requires_grad=False).cuda()\n        else:\n            images = Variable(images, requires_grad=False)\n            labels = Variable(labels, requires_grad=False)\n\n        # forward\n        logits = lprnet(images)\n        log_probs = logits.permute(2, 0, 1) # for ctc loss: T x N x C\n        log_probs = log_probs.log_softmax(2).requires_grad_()\n        # log_probs = log_probs.detach().requires_grad_()\n        # backprop\n        optimizer.zero_grad()\n        loss = ctc_loss(log_probs, labels, input_lengths=input_lengths, target_lengths=target_lengths)\n        if loss.item() == np.inf:\n            continue\n        loss.backward()\n        optimizer.step()\n        loss_val += loss.item()\n        end_time = time.time()\n        if iteration % 20 == 0:\n            print('Epoch:' + repr(epoch) + ' || epochiter: ' + repr(iteration % epoch_size) + '/' + repr(epoch_size)\n                  + '|| Totel iter ' + repr(iteration) + ' || Loss: %.4f||' % (loss.item()) +\n                  'Batch time: %.4f sec. ||' % (end_time - start_time) + 'LR: %.8f' % (lr))\n    # final test\n    print(\"Final test Accuracy:\")\n    Greedy_Decode_Eval(lprnet, test_dataset, args)\n\n    # save final parameters\n    torch.save(lprnet.state_dict(), args.save_folder + 'Final_LPRNet_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-10-03T10:19:50.857126Z","iopub.execute_input":"2024-10-03T10:19:50.857575Z","iopub.status.idle":"2024-10-03T10:19:50.883337Z","shell.execute_reply.started":"2024-10-03T10:19:50.857534Z","shell.execute_reply":"2024-10-03T10:19:50.882159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train()","metadata":{"execution":{"iopub.status.busy":"2024-10-03T10:19:52.939703Z","iopub.execute_input":"2024-10-03T10:19:52.940147Z","iopub.status.idle":"2024-10-03T10:32:55.874553Z","shell.execute_reply.started":"2024-10-03T10:19:52.940109Z","shell.execute_reply":"2024-10-03T10:32:55.873416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"import argparse\nimport sys\n\ndef get_parser():\n    parser = argparse.ArgumentParser(description='Parameters to train the LPRNet model.')\n    \n    parser.add_argument('--img_size', type=int, nargs=2, default=(94, 24),\n                        help='The image size as two integers, width and height.')\n    parser.add_argument('--test_img_dirs', default=\"/kaggle/working/processed_images/test\",\n                        help='Path to the test images directory.')\n    parser.add_argument('--dropout_rate', type=float, default=0.0,\n                        help='Dropout rate for the model.')\n    parser.add_argument('--lpr_max_len', type=int, default=15,\n                        help='Maximum length of the license plate number.')\n    parser.add_argument('--test_batch_size', type=int, default=22,\n                        help='Testing batch size.')\n    parser.add_argument('--phase_train', type=bool, default=False,\n                        help='Train or test phase flag (True for training, False for testing).')\n    parser.add_argument('--num_workers', type=int, default=8,\n                        help='Number of workers used in data loading.')\n    parser.add_argument('--cuda', type=bool, default=True,\n                        help='Use CUDA for training the model.')\n    parser.add_argument('--show', type=bool, default=True,\n                        help='Whether to show test images and their predicted results.')\n    parser.add_argument('--pretrained_model', \n                        default='/kaggle/input/pretrained/Final_LPRNet_model.pth',\n                        help='Path to the pretrained model.')\n\n    # Check if we are running in Jupyter Notebook\n    if 'ipykernel' in sys.modules:\n        return parser.parse_args([])  # Parse with no arguments for Jupyter\n\n    return parser.parse_args()  # Normal parsing for command line\n","metadata":{"execution":{"iopub.status.busy":"2024-10-03T10:17:25.801265Z","iopub.execute_input":"2024-10-03T10:17:25.801705Z","iopub.status.idle":"2024-10-03T10:17:25.812691Z","shell.execute_reply.started":"2024-10-03T10:17:25.801665Z","shell.execute_reply":"2024-10-03T10:17:25.811776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Greedy_Decode_Eval(Net, datasets, args):\n    epoch_size = len(datasets) // args.test_batch_size\n    batch_iterator = iter(DataLoader(datasets, args.test_batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=collate_fn))\n\n    Tp = 0\n    Tn_1 = 0\n    Tn_2 = 0\n    t1 = time.time()\n\n    for i in range(epoch_size):\n        images, labels, lengths = next(batch_iterator)\n        start = 0\n        \n        # Creating targets as an object array to accommodate varying lengths\n        targets = np.empty(len(lengths), dtype=object)\n        for idx, length in enumerate(lengths):\n            targets[idx] = labels[start:start + length]\n            start += length\n        \n        imgs = images.numpy().copy()\n\n        if args.cuda:\n            images = Variable(images.cuda())\n        else:\n            images = Variable(images)\n\n        # Forward pass\n        prebs = Net(images)\n        prebs = prebs.cpu().detach().numpy()\n        preb_labels = []\n\n        for i in range(prebs.shape[0]):\n            preb = prebs[i, :, :]\n            preb_label = []\n            for j in range(preb.shape[1]):\n                preb_label.append(np.argmax(preb[:, j], axis=0))\n            no_repeat_blank_label = []\n            pre_c = preb_label[0]\n            if pre_c != len(CHARS) - 1:\n                no_repeat_blank_label.append(pre_c)\n            for c in preb_label:\n                if (pre_c == c) or (c == len(CHARS) - 1):\n                    if c == len(CHARS) - 1:\n                        pre_c = c\n                    continue\n                no_repeat_blank_label.append(c)\n                pre_c = c\n            preb_labels.append(no_repeat_blank_label)\n\n        for i, label in enumerate(preb_labels):\n            if args.show:\n                print(f\"Showing image {i}, label: {label}, target: {targets[i]}\")\n                if imgs[i].shape[0] == 0 or imgs[i].shape[1] == 0:\n                    print(f\"Empty image at index {i}, skipping...\")\n                    continue\n                show(imgs[i], label, targets[i])\n            if len(label) != len(targets[i]):\n                Tn_1 += 1\n                continue\n            if (np.asarray(targets[i]) == np.asarray(label)).all():\n                Tp += 1\n            else:\n                Tn_2 += 1\n\n    total_predictions = Tp + Tn_1 + Tn_2\n    Acc = Tp * 1.0 / total_predictions if total_predictions > 0 else 0.0\n    \n    print(\"[Info] Test Accuracy: {} [{}:{}:{}:{}]\".format(Acc, Tp, Tn_1, Tn_2, total_predictions))\n    t2 = time.time()\n    print(\"[Info] Test Speed: {}s 1/{}]\".format((t2 - t1) / len(datasets), len(datasets)))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-03T10:17:26.853255Z","iopub.execute_input":"2024-10-03T10:17:26.853992Z","iopub.status.idle":"2024-10-03T10:17:26.871543Z","shell.execute_reply.started":"2024-10-03T10:17:26.853932Z","shell.execute_reply":"2024-10-03T10:17:26.870538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw, ImageFont\n\n# Function to show the image with label and target\ndef show(img, label, target):\n    # Transpose and adjust the image\n    img = np.transpose(img, (1, 2, 0))\n    img *= 128.\n    img += 127.5\n    img = img.astype(np.uint8)\n\n    lb = \"\"\n    for i in label:\n        lb += CHARS[i]  # Assuming CHARS is predefined\n    tg = \"\"\n    for j in target.tolist():\n        tg += CHARS[int(j)]\n\n    flag = \"T\" if lb == tg else \"F\"\n\n    # Add text to the image\n    img = cv2ImgAddText(img, lb, (0, 0))\n    \n    # Display image using matplotlib\n    plt.imshow(img)\n    plt.title(f\"Target: {tg} | Predict: {lb} | Match: {flag}\")\n    plt.axis('off')  # Hide axis\n    plt.show()\n\ndef cv2ImgAddText(img, text, pos, textColor=(255, 0, 0), textSize=12):\n    if isinstance(img, np.ndarray):  # Check if it's a valid OpenCV image format\n        img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))  # Convert to PIL format\n    draw = ImageDraw.Draw(img)\n    # Use a default font\n    fontText = ImageFont.load_default()  # Use default font\n    draw.text(pos, text, textColor, font=fontText)\n\n    return cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T10:17:28.013705Z","iopub.execute_input":"2024-10-03T10:17:28.014147Z","iopub.status.idle":"2024-10-03T10:17:28.025483Z","shell.execute_reply.started":"2024-10-03T10:17:28.014107Z","shell.execute_reply":"2024-10-03T10:17:28.024333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test():\n    args = get_parser()\n\n    lprnet = build_lprnet(lpr_max_len=args.lpr_max_len, phase=args.phase_train, class_num=len(CHARS), dropout_rate=args.dropout_rate)\n    device = torch.device(\"cuda:0\" if args.cuda else \"cpu\")\n    lprnet.to(device)\n    print(\"Successful to build network!\")\n\n    # load pretrained model\n    if args.pretrained_model:\n        lprnet.load_state_dict(torch.load(args.pretrained_model))\n        print(\"load pretrained model successful!\")\n    else:\n        print(\"[Error] Can't find pretrained mode, please check!\")\n        return False\n\n    test_img_dirs = os.path.expanduser(args.test_img_dirs)\n    test_dataset = LPRDataLoader(test_img_dirs.split(','), args.img_size, args.lpr_max_len)\n    try:\n        Greedy_Decode_Eval(lprnet, test_dataset, args)\n    finally:\n#         cv2.destroyAllWindows()\n        pass\n","metadata":{"execution":{"iopub.status.busy":"2024-10-03T10:17:28.72706Z","iopub.execute_input":"2024-10-03T10:17:28.727762Z","iopub.status.idle":"2024-10-03T10:17:28.735527Z","shell.execute_reply.started":"2024-10-03T10:17:28.727703Z","shell.execute_reply":"2024-10-03T10:17:28.734453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test()","metadata":{"execution":{"iopub.status.busy":"2024-10-03T10:17:29.500814Z","iopub.execute_input":"2024-10-03T10:17:29.501711Z","iopub.status.idle":"2024-10-03T10:17:41.731994Z","shell.execute_reply.started":"2024-10-03T10:17:29.501671Z","shell.execute_reply":"2024-10-03T10:17:41.730791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}